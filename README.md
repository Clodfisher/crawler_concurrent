# crawler_concurrent    

### 创建意图    

该项目用于实现并发版爬虫，对于网站进行有些数据的提取、存储、查找、以及页面展示。    

### 实现路程    

先实现单任务版本、随后实现并发版本、最终实现分布式版本。     
